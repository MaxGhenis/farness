{
  "case_id": "feature_build",
  "condition": "farness",
  "run_number": 3,
  "reframe_count": 7,
  "reframe_matches": [
    "opportunity cost",
    "alternative",
    "responsive",
    "PWA",
    "progressive web",
    "nice to have",
    "validate"
  ],
  "introduced_new_kpis": false,
  "challenged_framing": false,
  "response_text": "# Decision Analysis: Mobile App for B2B SaaS\n\n## Step 1: Define Measurable KPIs\n\n| KPI | Definition | Time Horizon |\n|-----|-----------|--------------|\n| **KPI 1: Net Revenue Retention (NRR)** | Revenue impact from reduced churn + expansion, attributable to mobile | 12 months post-launch |\n| **KPI 2: ROI** | (Incremental revenue - total cost) / total cost | 18 months post-launch |\n| **KPI 3: Mobile Engagement Rate** | % of active users using mobile \u22651x/week | 6 months post-launch |\n\n---\n\n## Step 2: Identify Options\n\n| # | Option | Description |\n|---|--------|-------------|\n| **A** | Build native app | Full iOS/Android native apps \u2014 $200K, 4 months |\n| **B** | Progressive Web App (PWA) | Optimize existing web app for mobile with offline support \u2014 ~$40-60K, 6-8 weeks |\n| **C** | Responsive redesign | Make current web app properly mobile-responsive \u2014 ~$20-40K, 3-4 weeks |\n| **D** | React Native / cross-platform app | Single codebase mobile app \u2014 ~$120-150K, 3 months |\n| **E** | Do nothing | Status quo, invest $200K elsewhere |\n\n---\n\n## Step 3: Point Estimates & Confidence Intervals\n\n### KPI 1: NRR Impact (percentage point change over baseline)\n\n| Option | Point Estimate | 80% CI | Reasoning |\n|--------|---------------|--------|-----------|\n| A \u2014 Native | +3 pp | [+0.5, +6] | Some churn saves, but mobile rarely the primary retention driver in B2B |\n| B \u2014 PWA | +2 pp | [+0.5, +4] | Captures ~60-70% of the mobile value at fraction of cost |\n| C \u2014 Responsive | +1 pp | [+0, +2.5] | Removes friction but doesn't create new engagement patterns |\n| D \u2014 Cross-platform | +2.5 pp | [+0.5, +5] | Near-native experience, slightly lower quality ceiling |\n| E \u2014 Do nothing | +0 pp | [-1, +0.5] | Risk of churn if competitors offer mobile; small negative skew |\n\n### KPI 2: 18-Month ROI\n\n| Option | Point Estimate | 80% CI | Reasoning |\n|--------|---------------|--------|-----------|\n| A \u2014 Native | -15% | [-60%, +40%] | High cost, uncertain adoption; needs ~$230K incremental revenue to break even |\n| B \u2014 PWA | +80% | [+10%, +200%] | Low cost base makes positive ROI much more achievable |\n| C \u2014 Responsive | +100% | [+20%, +250%] | Lowest cost, easiest ROI threshold |\n| D \u2014 Cross-platform | +10% | [-40%, +80%] | Moderate cost, moderate return profile |\n| E \u2014 Do nothing | 0% | [-15%, +5%] | Capital preserved but opportunity cost of alternative investments |\n\n### KPI 3: Mobile Weekly Engagement Rate\n\n| Option | Point Estimate | 80% CI | Reasoning |\n|--------|---------------|--------|-----------|\n| A \u2014 Native | 25% | [10%, 40%] | Best experience but B2B workflows are often desktop-centric |\n| B \u2014 PWA | 18% | [8%, 30%] | Good enough for most use cases; no app store friction |\n| C \u2014 Responsive | 12% | [5%, 20%] | Usable but not compelling enough to shift habits |\n| D \u2014 Cross-platform | 22% | [10%, 35%] | Close to native; app store presence helps discovery |\n| E \u2014 Do nothing | 5% | [2%, 10%] | Current painful-but-functional baseline |\n\n---\n\n## Step 4: Relevant Base Rates (Outside View)\n\n- **B2B mobile app adoption**: Typically only **20-35% of B2B users** regularly engage via mobile apps (Mixpanel, Pendo industry benchmarks). The \"vocal requesters\" are usually a loud minority.\n- **Feature request reliability**: ~65% of explicitly requested features see **less than 30% adoption** by the requesters themselves (Pendo 2023 State of Product).\n- **B2B SaaS churn attribution**: Mobile access is cited as a churn factor in only **5-12%** of exit surveys for desktop-first B2B tools (Gainsight benchmarks).\n- **PWA vs. Native satisfaction**: For non-consumer, utility-focused apps, PWAs achieve **70-85% of native user satisfaction scores** (Google case studies, Gartner).\n- **200-customer cohort**: At this scale, each customer represents 0.5% of revenue. Losing even 2-3 due to mobile gaps is meaningful (~1-1.5% revenue).\n\n---\n\n## Step 5: Cognitive Biases in the Framing\n\n| Bias | How It Appears Here |\n|------|-------------------|\n| **Availability bias** | \"Users have been asking\" \u2014 squeaky wheel effect. How many of the 200? 10? 50? Request frequency \u2260 actual demand magnitude |\n| **Anchoring on the presented option** | The question frames this as binary (build native or don't). Four other options exist. The $200K/4-month anchor makes a PWA feel \"cheap\" when it should be evaluated on its own merits |\n| **Build bias / IKEA effect** | Teams overvalue building something new vs. optimizing what exists. A responsive redesign may solve 80% of the pain |\n| **Survivorship bias in requests** | You hear from customers who stayed and want mobile. You *don't* hear from prospects who bounced because of poor mobile \u2014 or from customers for whom mobile is irrelevant |\n| **Commitment escalation risk** | 4-month native builds frequently become 7-9 months with scope creep in practice, turning a $200K project into $350K+ |\n\n---\n\n## Step 6: Recommendation\n\n### \u27a1\ufe0f **Recommended: Option B (PWA) with a validation gate before Option D**\n\n**Expected Value Calculation (simplified, 18-month horizon):**\n\nAssuming average revenue per customer of ~$15K ARR (total ~$3M ARR):\n\n| Option | Expected Incremental Revenue | Cost | Expected Net Value |\n|--------|------------------------------|------|-------------------|\n| A \u2014 Native | ~$90K (+3pp NRR \u00d7 $3M) | $200K (likely $280K+ realized) | **-$130K** |\n| B \u2014 PWA | ~$60K (+2pp NRR \u00d7 $3M) | $50K | **+$10K to +$60K** |\n| C \u2014 Responsive | ~$30K | $30K | **~$0 (break-even)** |\n| D \u2014 Cross-platform | ~$75K | $135K | **-$60K** |\n\n**The case for the PWA:**\n\n1. **Best risk-adjusted ROI** \u2014 highest expected value, tightest confidence interval around positive outcomes\n2. **Speed to learning** \u2014 deployed in 6-8 weeks, giving you real engagement data before committing to a larger investment\n3. **Reversibility** \u2014 if adoption is low, you've spent $50K learning that, not $200K+\n4. **Validation gate** \u2014 if PWA mobile engagement exceeds 25% weekly active, that's a strong signal to invest in native/cross-platform. If it's below 12%, you've confirmed mobile is a \"nice to have,\" not a retention driver.\n\n### Immediate Next Steps\n\n1. **Quantify actual demand**: Survey all 200 customers. How many would use mobile weekly? For what tasks specifically?\n2. **Build the PWA** with analytics instrumented from day one\n3. **Set a 90-day decision gate**: If mobile WAU > 25%, greenlight cross-platform app. If < 12%, stop.\n4. **Track churn conversations**: Add \"mobile access\" as an explicit field in churn/NPS surveys to get real attribution data\n\n> **Bottom line**: The native app is a $200K answer to a question you haven't validated yet. Spend $50K to ask the question properly first.",
  "timestamp": "2026-02-16T16:38:23.480437",
  "duration_seconds": 46.36244797706604
}